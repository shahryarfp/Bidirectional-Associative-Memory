{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0974fe",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef405e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1064f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "name_1 = np.array([1,0,0,0,0,1,1,  1,1,0,1,1,0,0,  1,1,0,1,0,0,1,  1,1,0,1,1,1,0,  1,1,1,0,1,0,0,\\\n",
    "                   1,1,0,1,1,1,1,  1,1,0,1,1,1,0])\n",
    "name_2 = np.array([1,0,0,1,0,0,0,  1,1,0,1,0,0,1,  1,1,0,1,1,0,0,  1,1,0,1,1,0,0,  1,1,0,0,0,0,1,\\\n",
    "                   1,1,1,0,0,1,0,  1,1,1,1,0,0,1])\n",
    "name_3 = np.array([1,0,0,1,0,1,1,  1,1,0,0,1,0,1,  1,1,0,1,1,1,0,  1,1,1,0,0,1,1,  1,1,1,0,1,0,0,\\\n",
    "                   1,1,0,0,0,0,1,  1,1,1,0,0,1,0])\n",
    "\n",
    "feature_1 = np.array([1,0,1,0,0,0,0, 1,1,1,0,0,1,0, 1,1,0,0,1,0,1, 1,1,1,0,0,1,1, 1,1,0,1,0,0,1,\\\n",
    "                      1,1,0,0,1,0,0, 1,1,0,0,1,0,1, 1,1,0,1,1,1,0, 1,1,1,0,1,0,0])\n",
    "feature_2 = np.array([1,0,0,0,1,1,0, 1,1,0,1,0,0,1, 1,1,1,0,0,1,0, 1,1,1,0,0,1,1, 1,1,1,0,1,0,0,\\\n",
    "                      1,0,0,1,1,0,0, 1,1,0,0,0,0,1, 1,1,0,0,1,0,0, 1,1,1,1,0,0,1])\n",
    "feature_3 = np.array([1,0,0,0,1,1,1, 1,1,0,0,1,0,1, 1,1,0,1,1,1,0, 1,1,1,0,1,0,0, 1,1,0,1,1,0,0,\\\n",
    "                      1,1,0,0,1,0,1, 1,1,0,1,1,0,1, 1,1,0,0,0,0,1, 1,1,0,1,1,1,0])\n",
    "\n",
    "my_dictionary = {\n",
    "    'Clinton':name_1,\n",
    "    'Hillary':name_2,\n",
    "    'Kenstar':name_3,\n",
    "    \n",
    "    'President': feature_1,\n",
    "    'FirstLady': feature_2,\n",
    "    'Gentleman': feature_3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e78e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting datas to bipolar\n",
    "\n",
    "def convert_to_bipolar(vector_):\n",
    "    for i in range(len(vector_)):\n",
    "        if vector_[i] == 0:\n",
    "            vector_[i] = -1\n",
    "\n",
    "convert_to_bipolar(name_1)\n",
    "convert_to_bipolar(name_2)\n",
    "convert_to_bipolar(name_3)\n",
    "convert_to_bipolar(feature_1)\n",
    "convert_to_bipolar(feature_2)\n",
    "convert_to_bipolar(feature_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae612f6",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "### Creating Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef95c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrix Shape: (49, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3., -3., -1., ...,  1., -1., -1.],\n",
       "       [-3.,  3.,  1., ..., -1.,  1.,  1.],\n",
       "       [-3.,  3.,  1., ..., -1.,  1.,  1.],\n",
       "       ...,\n",
       "       [-1.,  1.,  3., ...,  1., -1., -1.],\n",
       "       [ 1., -1.,  1., ...,  3.,  1., -3.],\n",
       "       [-1.,  1., -1., ..., -3., -1.,  3.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = np.zeros((len(name_1),len(feature_1)))\n",
    "def update_weight(name_, feature_):\n",
    "    for i in range(len(name_)):\n",
    "        for j in range(len(feature_)):\n",
    "            weight_matrix[i][j] += name_[i]*feature_[j]\n",
    "\n",
    "update_weight(name_1, feature_1)\n",
    "update_weight(name_2, feature_2)\n",
    "update_weight(name_3, feature_3)\n",
    "print('Weight Matrix Shape:', weight_matrix.shape)\n",
    "weight_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca68337",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc020ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sign(vector_):\n",
    "    for i in range(len(vector_)):\n",
    "        if vector_[i] >=0:\n",
    "            vector_[i] = 1\n",
    "        else :\n",
    "            vector_[i] = -1\n",
    "    return vector_\n",
    "\n",
    "def is_same(v1, v2):\n",
    "    if len(v1) != len(v2):\n",
    "        return False\n",
    "    for i in range(len(v1)):\n",
    "        if v1[i] != v2[i]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61cb3531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_1 predicted correctly\n",
      "name_2 predicted correctly\n",
      "name_3 predicted correctly\n",
      "feature_1 predicted correctly\n",
      "feature_2 predicted correctly\n",
      "feature_3 predicted correctly\n"
     ]
    }
   ],
   "source": [
    "predicted_name_1 = my_sign(np.matmul(name_1, weight_matrix))\n",
    "if is_same(predicted_name_1, feature_1):\n",
    "    print('name_1 predicted correctly')\n",
    "predicted_name_2 = my_sign(np.matmul(name_2, weight_matrix))\n",
    "if is_same(predicted_name_2, feature_2):\n",
    "    print('name_2 predicted correctly')\n",
    "predicted_name_3 = my_sign(np.matmul(name_3, weight_matrix))\n",
    "if is_same(predicted_name_3, feature_3):\n",
    "    print('name_3 predicted correctly')\n",
    "\n",
    "predicted_feature_1 = my_sign(np.matmul(feature_1, weight_matrix.T))\n",
    "if is_same(predicted_feature_1, name_1):\n",
    "    print('feature_1 predicted correctly')\n",
    "predicted_feature_2 = my_sign(np.matmul(feature_2, weight_matrix.T))\n",
    "if is_same(predicted_feature_2, name_2):\n",
    "    print('feature_2 predicted correctly')\n",
    "predicted_feature_3 = my_sign(np.matmul(feature_3, weight_matrix.T))\n",
    "if is_same(predicted_feature_3, name_3):\n",
    "    print('feature_3 predicted correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9f8a9",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "### Adding Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e0e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(vector__, noise):\n",
    "    vector_ = copy.deepcopy(vector__)\n",
    "    for i in range(len(vector_)):\n",
    "        rand = random.random()\n",
    "        if rand < noise:\n",
    "            vector_[i] *= -1\n",
    "    return vector_\n",
    "\n",
    "def activation_func(y_in_, y_in_prev):\n",
    "    y_in = copy.deepcopy(y_in_)\n",
    "    for i in range(len(y_in)):\n",
    "        if y_in[i] > 0:\n",
    "            y_in[i] = 1\n",
    "        elif y_in[i] == 0:\n",
    "            y_in[i] = y_in_prev[i]\n",
    "        elif y_in[i] < 0:\n",
    "            y_in[i] = -1\n",
    "    return y_in\n",
    "\n",
    "def calculate_accuracy(predicted, real):\n",
    "    count = 0\n",
    "    for i in range(len(real)):\n",
    "        if predicted[i] == real[i]:\n",
    "            count += 1\n",
    "    return count/len(real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9a23a",
   "metadata": {},
   "source": [
    "### Bidirectional Associative Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9e3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BAM(inputs, weight_matrix, outputs, noise, results_size):\n",
    "    results = np.zeros(results_size)\n",
    "    for i in range(len(inputs)):\n",
    "        for j in range(100):\n",
    "            n10_name_ = add_noise(inputs[i], noise)\n",
    "\n",
    "            #step 2a\n",
    "            x = n10_name_\n",
    "            x_prev = copy.deepcopy(x)\n",
    "            #step 2b\n",
    "            y_prev = np.zeros(len(outputs[0]))\n",
    "\n",
    "            #step 3\n",
    "            while True:\n",
    "                #step 4\n",
    "                y_in = np.matmul(x, weight_matrix)\n",
    "                y = activation_func(y_in, y_prev)\n",
    "\n",
    "                #step 5\n",
    "                x_in = np.matmul(y, weight_matrix.T)\n",
    "                x = activation_func(x_in, x_prev)\n",
    "                y_prev = copy.deepcopy(y)\n",
    "\n",
    "                #step 6\n",
    "                predicted_ans = activation_func(np.matmul(y, weight_matrix.T), x_prev)\n",
    "                if (x - x_prev).any() == 0:\n",
    "                    results[i] += calculate_accuracy(predicted_ans, names[i])\n",
    "                    break\n",
    "\n",
    "                x_prev = copy.deepcopy(x)\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89830f",
   "metadata": {},
   "source": [
    "### 10% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd23364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 10.0 %\n",
      "Name 1 Accuracy: 99.6734693877551\n",
      "Name 2 Accuracy: 100.0\n",
      "Name 3 Accuracy: 99.6734693877551\n",
      "Feature 1 Accuracy: 53.061224489795926\n",
      "Feature 2 Accuracy: 55.1020408163266\n",
      "Feature 3 Accuracy: 73.46938775510223\n"
     ]
    }
   ],
   "source": [
    "names = [name_1, name_2, name_3]\n",
    "features = [feature_1, feature_2, feature_3]\n",
    "noise = 0.1\n",
    "\n",
    "print('Noise:', noise*100,'%')\n",
    "results = BAM(names, weight_matrix, features, noise, 3)\n",
    "print('Name 1 Accuracy:', results[0])\n",
    "print('Name 2 Accuracy:', results[1])\n",
    "print('Name 3 Accuracy:', results[2])\n",
    "\n",
    "results = BAM(features, weight_matrix.T, names, noise, 3)\n",
    "print('Feature 1 Accuracy:', results[0])\n",
    "print('Feature 2 Accuracy:', results[1])\n",
    "print('Feature 3 Accuracy:', results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8e241",
   "metadata": {},
   "source": [
    "### 20% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a691ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 20.0 %\n",
      "Name 1 Accuracy: 98.85714285714285\n",
      "Name 2 Accuracy: 98.42857142857142\n",
      "Name 3 Accuracy: 98.3673469387755\n",
      "Feature 1 Accuracy: 53.10204081632654\n",
      "Feature 2 Accuracy: 55.22448979591844\n",
      "Feature 3 Accuracy: 73.42857142857162\n"
     ]
    }
   ],
   "source": [
    "noise = 0.2\n",
    "\n",
    "print('Noise:', noise*100,'%')\n",
    "results = BAM(names, weight_matrix, features, noise, 3)\n",
    "print('Name 1 Accuracy:', results[0])\n",
    "print('Name 2 Accuracy:', results[1])\n",
    "print('Name 3 Accuracy:', results[2])\n",
    "\n",
    "results = BAM(features, weight_matrix.T, names, noise, 3)\n",
    "print('Feature 1 Accuracy:', results[0])\n",
    "print('Feature 2 Accuracy:', results[1])\n",
    "print('Feature 3 Accuracy:', results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b73c65",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "### Adding another Data and doing all the previous steps again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed64790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lewisky\n",
    "name_4 = np.array([1,0,0,1,1,0,0, 1,1,0,0,1,0,1, 1,1,1,0,1,1,1, 1,1,0,1,0,0,1,\\\n",
    "                   1,1,1,0,0,1,1, 1,1,0,1,0,1,1, 1,1,1,1,0,0,1])\n",
    "#SweetGirl\n",
    "feature_4 = np.array([1,0,1,0,0,1,1, 1,1,1,0,1,1,1, 1,1,0,0,1,0,1, 1,1,0,0,1,0,1, 1,1,1,0,1,0,0,\\\n",
    "                      1,0,0,0,1,1,1, 1,1,0,1,0,0,1, 1,1,1,0,0,1,0, 1,1,0,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc09b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_bipolar(name_4)\n",
    "convert_to_bipolar(feature_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e4f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = np.zeros((len(name_1),len(feature_1)))\n",
    "def update_weight(name_, feature_):\n",
    "    for i in range(len(name_)):\n",
    "        for j in range(len(feature_)):\n",
    "            weight_matrix[i][j] += name_[i]*feature_[j]\n",
    "\n",
    "update_weight(name_1, feature_1)\n",
    "update_weight(name_2, feature_2)\n",
    "update_weight(name_3, feature_3)\n",
    "update_weight(name_4, feature_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f9dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_1 predicted correctly\n",
      "name_2 predicted correctly\n",
      "name_3 predicted correctly\n",
      "name_4 predicted correctly\n",
      "feature_1 predicted correctly\n",
      "feature_2 predicted correctly\n",
      "feature_3 predicted correctly\n"
     ]
    }
   ],
   "source": [
    "predicted_name_1 = my_sign(np.matmul(name_1, weight_matrix))\n",
    "if is_same(predicted_name_1, feature_1):\n",
    "    print('name_1 predicted correctly')\n",
    "predicted_name_2 = my_sign(np.matmul(name_2, weight_matrix))\n",
    "if is_same(predicted_name_2, feature_2):\n",
    "    print('name_2 predicted correctly')\n",
    "predicted_name_3 = my_sign(np.matmul(name_3, weight_matrix))\n",
    "if is_same(predicted_name_3, feature_3):\n",
    "    print('name_3 predicted correctly')\n",
    "predicted_name_4 = my_sign(np.matmul(name_4, weight_matrix))\n",
    "if is_same(predicted_name_4, feature_4):\n",
    "    print('name_4 predicted correctly')\n",
    "\n",
    "predicted_feature_1 = my_sign(np.matmul(feature_1, weight_matrix.T))\n",
    "if is_same(predicted_feature_1, name_1):\n",
    "    print('feature_1 predicted correctly')\n",
    "predicted_feature_2 = my_sign(np.matmul(feature_2, weight_matrix.T))\n",
    "if is_same(predicted_feature_2, name_2):\n",
    "    print('feature_2 predicted correctly')\n",
    "predicted_feature_3 = my_sign(np.matmul(feature_3, weight_matrix.T))\n",
    "if is_same(predicted_feature_3, name_3):\n",
    "    print('feature_3 predicted correctly')\n",
    "predicted_feature_4 = my_sign(np.matmul(feature_4, weight_matrix.T))\n",
    "if is_same(predicted_feature_4, name_4):\n",
    "    print('feature_4 predicted correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6f1de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 10.0 %\n",
      "Name 1 Accuracy: 98.40816326530611\n",
      "Name 2 Accuracy: 97.6326530612245\n",
      "Name 3 Accuracy: 97.02040816326534\n",
      "Name 3 Accuracy: 96.32653061224495\n",
      "Feature 1 Accuracy: 53.95918367346938\n",
      "Feature 2 Accuracy: 55.877551020408234\n",
      "Feature 3 Accuracy: 73.46938775510223\n",
      "Feature 3 Accuracy: 61.26530612244894\n"
     ]
    }
   ],
   "source": [
    "#10 % noise\n",
    "names = [name_1, name_2, name_3, name_4]\n",
    "features = [feature_1, feature_2, feature_3, feature_4]\n",
    "noise = 0.1\n",
    "\n",
    "print('Noise:', noise*100,'%')\n",
    "results = BAM(names, weight_matrix, features, noise, 4)\n",
    "print('Name 1 Accuracy:', results[0])\n",
    "print('Name 2 Accuracy:', results[1])\n",
    "print('Name 3 Accuracy:', results[2])\n",
    "print('Name 3 Accuracy:', results[3])\n",
    "\n",
    "results = BAM(features, weight_matrix.T, names, noise, 4)\n",
    "print('Feature 1 Accuracy:', results[0])\n",
    "print('Feature 2 Accuracy:', results[1])\n",
    "print('Feature 3 Accuracy:', results[2])\n",
    "print('Feature 3 Accuracy:', results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014e00d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise: 20.0 %\n",
      "Name 1 Accuracy: 97.14285714285714\n",
      "Name 2 Accuracy: 96.40816326530614\n",
      "Name 3 Accuracy: 96.89795918367348\n",
      "Name 3 Accuracy: 94.24489795918369\n",
      "Feature 1 Accuracy: 54.65306122448979\n",
      "Feature 2 Accuracy: 56.32653061224495\n",
      "Feature 3 Accuracy: 73.46938775510223\n",
      "Feature 3 Accuracy: 61.02040816326527\n"
     ]
    }
   ],
   "source": [
    "#20 % noise\n",
    "noise = 0.2\n",
    "\n",
    "print('Noise:', noise*100,'%')\n",
    "results = BAM(names, weight_matrix, features, noise, 4)\n",
    "print('Name 1 Accuracy:', results[0])\n",
    "print('Name 2 Accuracy:', results[1])\n",
    "print('Name 3 Accuracy:', results[2])\n",
    "print('Name 3 Accuracy:', results[3])\n",
    "\n",
    "results = BAM(features, weight_matrix.T, names, noise, 4)\n",
    "print('Feature 1 Accuracy:', results[0])\n",
    "print('Feature 2 Accuracy:', results[1])\n",
    "print('Feature 3 Accuracy:', results[2])\n",
    "print('Feature 3 Accuracy:', results[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
